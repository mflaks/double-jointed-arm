{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Control\n",
    "\n",
    "---\n",
    "\n",
    "You are welcome to use this coding environment to train your agent for the project.  Follow the instructions below to get started!\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "Run the next code cell to install a few packages.  This line will take a few minutes to run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mtensorflow 1.7.1 has requirement numpy>=1.13.3, but you'll have numpy 1.12.1 which is incompatible.\u001b[0m\r\n",
      "\u001b[31mipython 6.5.0 has requirement prompt-toolkit<2.0.0,>=1.0.15, but you'll have prompt-toolkit 3.0.4 which is incompatible.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip -q install ./python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The environments corresponding to both versions of the environment are already saved in the Workspace and can be accessed at the file paths provided below.  \n",
    "\n",
    "Please select one of the two options below for loading the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_speed -> 1.0\n",
      "\t\tgoal_size -> 5.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "\n",
    "# select this option to load version 1 (with a single agent) of the environment\n",
    "env = UnityEnvironment(file_name='/data/Reacher_One_Linux_NoVis/Reacher_One_Linux_NoVis.x86_64')\n",
    "\n",
    "# select this option to load version 2 (with 20 agents) of the environment\n",
    "# env = UnityEnvironment(file_name='/data/Reacher_Linux_NoVis/Reacher.x86_64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 1\n",
      "Size of each action: 4\n",
      "There are 1 agents. Each observes a state with length: 33\n",
      "The state for the first agent looks like: [  0.00000000e+00  -4.00000000e+00   0.00000000e+00   1.00000000e+00\n",
      "  -0.00000000e+00  -0.00000000e+00  -4.37113883e-08   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00  -1.00000000e+01   0.00000000e+00\n",
      "   1.00000000e+00  -0.00000000e+00  -0.00000000e+00  -4.37113883e-08\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   5.75471878e+00  -1.00000000e+00\n",
      "   5.55726671e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00\n",
      "  -1.68164849e-01]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents\n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agent and receive feedback from the environment.\n",
    "\n",
    "Note that **in this coding environment, you will not be able to watch the agents while they are training**, and you should set `train_mode=True` to restart the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total score (averaged over agents) this episode: 0.05999999865889549\n"
     ]
    }
   ],
   "source": [
    "env_info = env.reset(train_mode=True)[brain_name]      # reset the environment    \n",
    "states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "while True:\n",
    "    actions = np.random.randn(num_agents, action_size) # select an action (for each agent)\n",
    "    actions = np.clip(actions, -1, 1)                  # all actions between -1 and 1\n",
    "    env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "    next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "    rewards = env_info.rewards                         # get reward (for each agent)\n",
    "    dones = env_info.local_done                        # see if episode finished\n",
    "    scores += env_info.rewards                         # update the score (for each agent)\n",
    "    states = next_states                               # roll over states to next time step\n",
    "    if np.any(dones):                                  # exit loop if episode finished\n",
    "        break\n",
    "print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. It's Your Turn!\n",
    "\n",
    "Now it's your turn to train your own agent to solve the environment!  A few **important notes**:\n",
    "- When training the environment, set `train_mode=True`, so that the line for resetting the environment looks like the following:\n",
    "```python\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "```\n",
    "- To structure your work, you're welcome to work directly in this Jupyter notebook, or you might like to start over with a new file!  You can see the list of files in the workspace by clicking on **_Jupyter_** in the top left corner of the notebook.\n",
    "- In this coding environment, you will not be able to watch the agents while they are training.  However, **_after training the agents_**, you can download the saved model weights to watch the agents on your own machine! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pickle\n",
    "\n",
    "\n",
    "# it will send the tensor to CPU or GPU (if available)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Create a Replay Buffer to store the experience (State, Action, Reward, Done).\n",
    "class ReplayBuffer:\n",
    "\n",
    "    def __init__(self, memory_size, state_dims, n_actions):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "        memory_size -- scalar, total number of experiences that the Replay Buffer can store\n",
    "        state_dim -- list, the size of the state Example: Vector  [10], pixels [80,80]\n",
    "        action_dim -- list, the size of the action\n",
    "        \"\"\"\n",
    "\n",
    "        self.memory_size = memory_size\n",
    "        self.state = np.zeros((memory_size, state_dims))\n",
    "        self.action = np.zeros((memory_size, n_actions))\n",
    "        self.reward = np.zeros((memory_size, 1))\n",
    "        self.next_state = np.zeros((memory_size, state_dims))\n",
    "        self.done = np.zeros((memory_size, 1))\n",
    "        self.count = 0\n",
    "        self.index = 0\n",
    "\n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "\n",
    "        # store the experience on the position = Index    \n",
    "        # state, action, reward, next_state ==>  type(numpy array)\n",
    "        self.state[self.index] = state\n",
    "        self.action[self.index] = action\n",
    "        self.reward[self.index] = reward\n",
    "        self.next_state[self.index] = next_state\n",
    "        self.done[self.index] = done\n",
    "\n",
    "        # define the position (index) where we want to store the next experience\n",
    "        if self.index == self.memory_size - 1:\n",
    "            self.index = 0\n",
    "        else:\n",
    "            self.index = self.index + 1\n",
    "\n",
    "        # keep track of total experiences we already saved\n",
    "        self.count = self.count + 1\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "\n",
    "        # random select some examples from the Replay Buffer\n",
    "        idx = np.random.choice(np.arange(min(self.count, self.memory_size)), batch_size)\n",
    "        states = self.state[idx]\n",
    "        actions = self.action[idx]\n",
    "        rewards = self.reward[idx]\n",
    "        next_states = self.next_state[idx]\n",
    "        dones = self.done[idx]\n",
    "\n",
    "        return states, actions, rewards, next_states, dones\n",
    "\n",
    "\n",
    "# Create a Noise to add in the action in order to make the agent explore the environment: Ornstein–Uhlenbeck (OU)\n",
    "class OUActionNoise:\n",
    "    def __init__(self, mu=np.array([[0,0,0,0]]), theta=0.03, sigma=0.03, dt=0.01, x0=None):\n",
    "        self.mu = mu                                # np.array shape [1, n_actions], the noise will converge to mu\n",
    "        self.theta = theta                          # scalar, how fast the noise will converge to mu\n",
    "        self.sigma = sigma                          # scalar, the volatility of the noise\n",
    "        self.dt = dt                                # scalar, how fast the noise will converge to mu\n",
    "        self.x0 = x0                                # np.array shape [1, n_actions], initial value of the noise\n",
    "        self.x_prev = self.x0\n",
    "        self.reset()\n",
    "\n",
    "    def __call__(self):\n",
    "        x = self.x_prev + self.theta * (self.mu - self.x_prev) * self.dt + self.sigma * np.sqrt(\n",
    "            self.dt) * np.random.normal(size=self.mu.shape)\n",
    "        self.x_prev = x\n",
    "        return x\n",
    "\n",
    "    def reset(self):\n",
    "        if self.x0 is None:\n",
    "            self.x_prev = np.zeros(self.mu.shape)\n",
    "\n",
    "            \n",
    "class Actor(nn.Module):\n",
    "    \"\"\"\n",
    "    Actor will be the policy.  It will choose the best action to take, one action for each State (Deterministic Policy)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, learning_rate, state_dims, n_actions, action_bound, fc1_dims, fc2_dims):\n",
    "        super(Actor, self).__init__()\n",
    "        self.learning_rate = learning_rate                   # learning rate\n",
    "        self.state_dim = state_dims                          # number of features on the state\n",
    "        self.n_actions = n_actions                           # number of actions\n",
    "        self.action_bound = action_bound                     # maximum absolute value of each action\n",
    "\n",
    "        # Create the Layers and initialize the parameters according the paper DDPG\n",
    "        self.fc1 = nn.Linear(in_features=state_dims, out_features=fc1_dims)\n",
    "        self.fc2 = nn.Linear(in_features=fc1_dims, out_features=fc2_dims)\n",
    "        self.fc3 = nn.Linear(in_features=fc2_dims, out_features=n_actions)\n",
    "\n",
    "\n",
    "        # initialize the parameters with a uniform distribution\n",
    "        # each number btw -f and f has the same probability to be chosen as a parameter (weight and bias)\n",
    "        f1 = 1 / np.sqrt(fc1_dims)\n",
    "        torch.nn.init.uniform_(self.fc1.weight, -f1, f1)\n",
    "        torch.nn.init.uniform_(self.fc1.bias, -f1, f1)\n",
    "\n",
    "        f2 = 1 / np.sqrt(fc2_dims)\n",
    "        torch.nn.init.uniform_(self.fc2.weight, -f2, f2)\n",
    "        torch.nn.init.uniform_(self.fc2.bias, -f2, f2)\n",
    "\n",
    "        f3 = 0.003\n",
    "        torch.nn.init.uniform_(self.fc3.weight, -f3, f3)\n",
    "        torch.nn.init.uniform_(self.fc3.bias, -f3, f3)\n",
    "        \n",
    "        # define the optimizer\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "\n",
    "    def forward(self, state):\n",
    "        \"\"\"\n",
    "        Argument:\n",
    "        s --   State, tensor shape(m_examples, n features)\n",
    "\n",
    "        Return\n",
    "        act --  Action, tensor shape(m_examples, n_actions)\n",
    "        \"\"\"\n",
    "        s = self.fc1(state)\n",
    "        s = F.relu(s)\n",
    "\n",
    "        s = self.fc2(s)\n",
    "        s = F.relu(s)\n",
    "\n",
    "        s = self.fc3(s)\n",
    "        s = torch.tanh(s)            # return values between [-1, 1]\n",
    "        act = s * self.action_bound  # return values between [-action bound , action bound]\n",
    "\n",
    "        return act\n",
    "\n",
    "    \n",
    "class Critic(nn.Module):\n",
    "    \"\"\"\n",
    "    Critic will calculate the Q value of the state_action pair Q(s,a)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, learning_rate, state_dim, n_actions, fc1_dims, fc2_dims):\n",
    "        super(Critic, self).__init__()\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        # Create the Layers and initialize  the parameters according the paper DDPG\n",
    "        self.fc1 = nn.Linear(in_features=state_dim + n_actions, out_features=fc1_dims)\n",
    "        self.fc2 = nn.Linear(in_features=fc1_dims, out_features=fc2_dims)\n",
    "        self.fc3 = nn.Linear(in_features=fc2_dims, out_features=1)  # output = 1 dimension Q(s,a)\n",
    "\n",
    "\n",
    "        # initialize the parameters with a uniform distribution\n",
    "        # each number btw -f and f has the same probability to be chosen as a parameter (weight and bias)\n",
    "        f1 = 1 / np.sqrt(fc1_dims)\n",
    "        nn.init.uniform_(self.fc1.weight, -f1, f1)\n",
    "        nn.init.uniform_(self.fc1.bias, -f1, f1)\n",
    "\n",
    "        f2 = 1 / np.sqrt((fc2_dims + n_actions))\n",
    "        nn.init.uniform_(self.fc2.weight, -f2, f2)\n",
    "        nn.init.uniform_(self.fc2.bias, -f2, f2)\n",
    "\n",
    "        f3 = 0.003\n",
    "        nn.init.uniform_(self.fc3.weight, -f3, f3)\n",
    "        nn.init.uniform_(self.fc3.bias, -f3, f3)\n",
    "\n",
    "\n",
    "        # define the optimizer\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "\n",
    "    def forward(self, state, action):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "        state --  State, tensor shape(m_examples, n_features)\n",
    "        action -- Action chosen by the Actor, tensor shape(m_examples, n_actions)\n",
    "\n",
    "        Return:\n",
    "        q -- Q(s,a) Total Discounted Return of the State_Action pair, tensor shape (m examples, n_actions)\n",
    "        \"\"\"\n",
    "\n",
    "        # include the action\n",
    "        s = torch.cat((state, action), dim=1)\n",
    "\n",
    "        s = self.fc1(s)\n",
    "        s = F.relu(s)\n",
    "        \n",
    "        s = self.fc2(s)\n",
    "        s = F.relu(s)\n",
    "\n",
    "        s = self.fc3(s)\n",
    "\n",
    "\n",
    "        return s\n",
    "\n",
    "\n",
    "# Create an Agent to interact with the environment\n",
    "class Agent:\n",
    "\n",
    "    def __init__(self, n_actions, action_bound, state_dim, alfa, beta, fc1_dims, fc2_dims, tau, gamma, batch_size,\n",
    "                 memory_size, episodic_task):\n",
    "        self.n_actions = n_actions                # scalar, number of actions\n",
    "        self.action_bound = action_bound          # scalar, maximum absolute value of the action\n",
    "        self.state_dim = state_dim                # scalar, number of features on the state\n",
    "        self.fc1_dims = fc1_dims                  # scalar, number of neurons on the 1st hidden layer\n",
    "        self.fc2_dims = fc2_dims                  # scalar, number of neurons on the 2nd hidden layer\n",
    "        self.alfa = alfa                          # scalar, learning rate of the Actor Network\n",
    "        self.beta = beta                          # scalar, learning rate of Critic, need to learn faster than the actor\n",
    "        self.tau = tau                            # scalar [0,1] Soft Update of Target Network: Actor and Critic << 1\n",
    "        self.gamma = gamma                        # scalar [0,1] Discount Rate for future rewards\n",
    "        self.batch_size = batch_size              # scalar, size of the mini batch - number os samples\n",
    "        self.memory_size = memory_size            # scalar, maximum number of experiences to store on Replay Buffer\n",
    "        self.episodic_task = episodic_task        # check if there is a terminal state\n",
    "\n",
    "        # create a Replay Buffer to store the experiences (Break the Correlation in order to train the model)\n",
    "        self.memory = ReplayBuffer(int(memory_size), state_dim, n_actions)\n",
    "\n",
    "        # create 4 networks: Actor / Actor_Target and  Critic / Critic_Target\n",
    "        self.actor = Actor(alfa, state_dim, n_actions, action_bound, fc1_dims, fc2_dims).to(device)\n",
    "        self.actor_target = Actor(alfa, state_dim, n_actions, action_bound, fc1_dims, fc2_dims).to(device)\n",
    "\n",
    "        self.critic = Critic(beta, state_dim, n_actions, fc1_dims, fc2_dims).to(device)\n",
    "        self.critic_target = Critic(beta, state_dim, n_actions, fc1_dims, fc2_dims).to(device)\n",
    "\n",
    "        # Initialize the Actor_Target and Critic_Target Parameters with the same values of the Actor and Critic tau=1\n",
    "        self.update_parameters(tau=1)\n",
    "\n",
    "        # initialize noise\n",
    "        self.noise = OUActionNoise()\n",
    "\n",
    "    def update_parameters(self, tau):\n",
    "\n",
    "        # Soft update Actor Target:  actor_target = (1-tau) * actor_target + tau * actor\n",
    "        for actor_target, actor in zip(self.actor_target.parameters(), self.actor.parameters()):\n",
    "            actor_target.data.copy_((1 - tau) * actor_target + tau * actor)\n",
    "\n",
    "        # Soft update Critic Target\n",
    "        for critic_target, critic in zip(self.critic_target.parameters(), self.critic.parameters()):\n",
    "            critic_target.data.copy_((1 - tau) * critic_target + tau * critic)\n",
    "\n",
    "    def choose_action(self, state, noise_decay):\n",
    "        # Convert the input to tensor\n",
    "        state = torch.tensor(state, dtype=torch.float32).to(device)\n",
    "\n",
    "        # The Critic Network will choose the best action and we will add a noise  (Exploration)\n",
    "        noise = self.noise()*noise_decay\n",
    "        action = np.array(self.actor(state).detach().to('cpu')) + noise\n",
    "\n",
    "        return action\n",
    "\n",
    "    def learn(self):\n",
    "\n",
    "        # the Agent will learn only if we have enough experiences stored on the memory\n",
    "        if self.memory.count >= self.batch_size:\n",
    "\n",
    "            # random choose some experiences (S, A, R, S', done) from the Memory\n",
    "            states, actions, rewards, next_states, dones = self.memory.sample(self.batch_size)\n",
    "\n",
    "            # convert the experience into tensors\n",
    "            states = torch.tensor(states, dtype=torch.float32).to(device)\n",
    "            actions = torch.tensor(actions, dtype=torch.float32).to(device)\n",
    "            rewards = torch.tensor(rewards, dtype=torch.float32).to(device)\n",
    "            next_states = torch.tensor(next_states, dtype=torch.float32).to(device)\n",
    "            dones = torch.tensor(dones, dtype=torch.float32).to(device)\n",
    "\n",
    "            ######################################     TRAIN CRITIC  ##################################################\n",
    "            # Find the Target to train the Critic Network.\n",
    "            # If there isn't a Terminal_State, the game just end because the agent reaches the maximum number of steps\n",
    "            # If there is Terminal State: Q_Value(terminal_State)=0 ==> done=1\n",
    "            actions_target = self.actor_target(next_states)\n",
    "            if self.episodic_task:\n",
    "                target = rewards + self.gamma * self.critic_target(next_states, actions_target) * (1 - dones)\n",
    "            else:\n",
    "                target = rewards + self.gamma * self.critic_target(next_states, actions_target)\n",
    "\n",
    "            # calculate the prediction of the Critic Network\n",
    "            prediction = self.critic(states, actions)\n",
    "\n",
    "            # calculate the loss of the Critic Network: Mean Square Error\n",
    "            loss_critic = F.mse_loss(input=prediction, target=target)\n",
    "\n",
    "            # zero previous gradients,  pytorch accumulates their values at each time we train the network\n",
    "            self.critic.optimizer.zero_grad()\n",
    "\n",
    "            # calculate the gradients\n",
    "            loss_critic.backward()\n",
    "\n",
    "            # update the parameters (weight and bias)\n",
    "            self.critic.optimizer.step()\n",
    "\n",
    "            ###################################     TRAIN ACTOR    ###################################################\n",
    "            # We want to decide if we need to increase or decrease the value of the action on the Actor Network in order\n",
    "            # to achieve a higher value of the Q(s, a) on the Critic Network.  Q(s,a) = Total Discounted Reward\n",
    "            critic_actions = self.actor(states)\n",
    "\n",
    "            q_state_action = self.critic(states, critic_actions)\n",
    "\n",
    "            # Find the Loss: Maximize f(x) = Minimize -f(x).\n",
    "            loss_actor = - torch.mean(q_state_action)\n",
    "\n",
    "            # zero previous gradients,  pytorch accumulates their values at each time we train the network\n",
    "            self.actor.optimizer.zero_grad()\n",
    "\n",
    "            # calculate the gradients\n",
    "            loss_actor.backward()\n",
    "\n",
    "            # update the parameters (weight and bias)\n",
    "            self.actor.optimizer.step()\n",
    "            ###########################################################################################################\n",
    "\n",
    "            # update parameters of the Actor_Target and Critic_Target with Soft Update\n",
    "            self.update_parameters(self.tau)\n",
    "\n",
    "            \n",
    "                           # DDPG DEEP DETERMINISTIC POLICY GRADIENT \n",
    "    \n",
    "# Create an Agent\n",
    "agent = Agent(n_actions=4, action_bound=1, state_dim=33, alfa=0.0003, beta=0.0003, fc1_dims=400, fc2_dims=300, tau=0.03,\n",
    "                  gamma=0.99, batch_size=32, memory_size=1e+5, episodic_task=False)\n",
    "\n",
    "# save score of each episode\n",
    "total_scores = []\n",
    "\n",
    "step = 0\n",
    "\n",
    "for episode in range(1, 1001):\n",
    "\n",
    "    # reset the environment\n",
    "    env_info = env.reset(train_mode=True)[brain_name]      # reset the environment    \n",
    "    state = env_info.vector_observations                   # get the current state (for each agent)\n",
    "\n",
    "    # reset the score of each episode\n",
    "    score = 0\n",
    "    \n",
    "    # decay de noise every episode\n",
    "    noise_decay = 0.97 ** episode\n",
    "    \n",
    "    while True:\n",
    "        step = step + 1\n",
    "\n",
    "        # agent will choose the best action to take\n",
    "        actions = agent.choose_action(state, noise_decay)\n",
    "        actions = np.clip(actions, -1, 1) \n",
    "\n",
    "        # take an action and receive a reward and go to the next_state\n",
    "        env_info = env.step(actions)[brain_name]             # send all actions to tne environment\n",
    "        next_state = env_info.vector_observations           # get next state (for each agent)\n",
    "        rewards = env_info.rewards                          # get reward (for each agent)\n",
    "        reward = np.array(rewards)\n",
    "        done = env_info.local_done                          # see if episode finished\n",
    "\n",
    "        # convert reward to a np, it was a list\n",
    "        reward = np.array(rewards)\n",
    "\n",
    "        # store the experiences\n",
    "        agent.memory.add(state, actions, reward, next_state, done)\n",
    "\n",
    "        # Train the model\n",
    "        if step % 6 ==0:\n",
    "            for i in range(4):\n",
    "                agent.learn()\n",
    "\n",
    "        # current state\n",
    "        state = next_state\n",
    "\n",
    "        # update score\n",
    "        score = score + reward\n",
    "\n",
    "        if np.any(done):\n",
    "            total_scores.append(score)\n",
    "            print('episode:{}.....reward:{:.2f}.....noise_decay:{:.2f}'.format(episode, float(score), noise_decay))\n",
    "            break\n",
    "        \n",
    "    # save parameters \n",
    "    if len(total_scores) >= 100:\n",
    "        if np.average(total_scores[-100:]) > 30:\n",
    "            torch.save(agent.actor.state_dict(), 'actor_parameters.pt')\n",
    "            torch.save(agent.actor_target.state_dict(), 'actor-target_parameters.pt')\n",
    "            torch.save(agent.critic.state_dict(), 'critic_parameters.pt')\n",
    "            torch.save(agent.critic_target.state_dict(), 'critic-target_parameters.pt')\n",
    "\n",
    "            # save list of total_scores\n",
    "            file_out = open('total_scores.pickle', 'wb')\n",
    "            pickle.dump(total_scores, file_out)\n",
    "            file_out.close() \n",
    "            print('problem solved!!!')\n",
    "            break\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f448aaa72e8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of episodes: 372\n",
      "average reward 100 consecutive episodes:30.59\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# load total rewards\n",
    "file_in = open('total_scores.pickle', 'rb')\n",
    "total_rewards = pickle.load(file_in)\n",
    "\n",
    "# plot all rewards\n",
    "plt.plot(total_rewards)\n",
    "\n",
    "average = []\n",
    "for i in range(100, len(total_rewards)):\n",
    "    average.append(np.average(total_rewards[i-100: i]))\n",
    "\n",
    "# plot the average reward of 100 conseutive episodes\n",
    "plt.plot(np.arange(100, len(total_rewards)), average)\n",
    "\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "print('number of episodes:', len(total_rewards))\n",
    "print('average reward 100 consecutive episodes:{:.2f}'.format(np.average(total_rewards[-100:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
